{
  "model": {
    "version": "full",
    "available_models": {
      "full": {
        "id": "mistralai/Voxtral-Mini-3B-2507",
        "name": "Voxtral Mini 3B (Full)",
        "size_gb": 9.36,
        "format": "safetensors",
        "quantization": null,
        "description": "Full precision model - Best quality, requires ~20-30GB RAM during loading (CPU loading: 10-30 min)",
        "memory_requirements": {
          "disk": "9.36 GB",
          "ram_loading": "20-30 GB (Windows: increase pagefile to 50GB)",
          "ram_inference": "10-12 GB",
          "load_time_cpu": "10-30 minutes (use NVIDIA GPU for faster loading)"
        }
      },
      "quantized": {
        "id": "mistralai/Voxtral-Mini-3B-2507",
        "name": "Voxtral Mini 3B (4-bit Quantized)",
        "size_gb": 9.36,
        "format": "safetensors",
        "quantization": "4bit",
        "description": "4-bit quantized model - 75% less memory usage (NVIDIA GPU required, auto-falls back to full precision on Mac/CPU)",
        "memory_requirements": {
          "disk": "9.36 GB (quantized during load)",
          "ram_loading": "5-8 GB (NVIDIA GPU) / 20-30GB (Mac/CPU fallback)",
          "ram_inference": "3-4 GB (NVIDIA GPU) / 10-12GB (Mac/CPU fallback)"
        }
      },
      "small-24b": {
        "id": "mistralai/Voxtral-Small-24B-2507",
        "name": "Voxtral Small 24B (Full)",
        "size_gb": 97.1,
        "format": "safetensors",
        "quantization": null,
        "description": "Large 24B model - Best quality and accuracy, requires high-end GPU with ~55GB VRAM or significant RAM",
        "memory_requirements": {
          "disk": "97.1 GB",
          "ram_loading": "55+ GB (GPU) / 100+ GB (CPU)",
          "ram_inference": "55 GB (GPU)",
          "load_time_cpu": "Not recommended - use GPU with 55+ GB VRAM"
        }
      },
      "small-24b-quantized": {
        "id": "mistralai/Voxtral-Small-24B-2507",
        "name": "Voxtral Small 24B (4-bit Quantized)",
        "size_gb": 97.1,
        "format": "safetensors",
        "quantization": "4bit",
        "description": "4-bit quantized 24B model - High quality with reduced memory, requires NVIDIA GPU with ~16GB VRAM",
        "memory_requirements": {
          "disk": "97.1 GB (quantized during load)",
          "ram_loading": "16-20 GB (NVIDIA GPU)",
          "ram_inference": "14-16 GB (NVIDIA GPU)",
          "load_time_cpu": "Not supported - requires NVIDIA GPU with CUDA"
        }
      }
    }
  },
  "app": {
    "version": "1.1.13",
    "name": "Voxtral Transcription"
  }
}